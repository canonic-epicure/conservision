{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:28.016163Z",
     "start_time": "2025-09-24T13:31:28.003925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "d1abdc2cda989cb8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.067129Z",
     "start_time": "2025-09-24T13:31:28.050147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import lib\n",
    "\n",
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ],
   "id": "c3c59e0a47e20c12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.097882Z",
     "start_time": "2025-09-24T13:31:30.071541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration class\n",
    "class CFG:\n",
    "    # File paths\n",
    "    BASE_PATH = Path('./data')\n",
    "    TRAIN_FEATURES_PATH = BASE_PATH / 'train_features.csv'\n",
    "    TRAIN_LABELS_PATH = BASE_PATH / 'train_labels.csv'\n",
    "    TEST_FEATURES_PATH = BASE_PATH / 'test_features.csv'\n",
    "\n",
    "    # RTX 5090 optimized settings\n",
    "    # MODEL_ARCHITECTURE = 'convnext_large_in22k'  # Upgraded to larger model\n",
    "    MODEL_ARCHITECTURE = 'timm/eva02_large_patch14_448.mim_m38m_ft_in22k_in1k'  # Upgraded to larger model\n",
    "\n",
    "    IMAGE_SIZE = 448      # Higher resolution\n",
    "    BATCH_SIZE = 16       # Optimized for RTX 5090\n",
    "    N_FOLDS = 5\n",
    "    EPOCHS = 15           # Moderate increase in training epochs\n",
    "\n",
    "    # RTX 5090 optimization\n",
    "    NUM_WORKERS = 12      # Optimized threading\n",
    "    PIN_MEMORY = True\n",
    "    PREFETCH_FACTOR = 4\n",
    "\n",
    "    # Competition settings\n",
    "    TARGET_COL = 'label'\n",
    "    SEED = 42\n",
    "    BASE_LR = 1e-3"
   ],
   "id": "b1a7b9d4a3351af7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.139026Z",
     "start_time": "2025-09-24T13:31:30.116188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"fast_ai_k_fold_data.pkl\", \"rb\") as f:\n",
    "    stats = pickle.load(f)\n"
   ],
   "id": "7e74068044861f74",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.433680Z",
     "start_time": "2025-09-24T13:31:30.161903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"RTX 5090 Configuration:\")\n",
    "print(f\"   Model: {CFG.MODEL_ARCHITECTURE}\")\n",
    "print(f\"   Resolution: {CFG.IMAGE_SIZE}x{CFG.IMAGE_SIZE}\")\n",
    "print(f\"   Batch Size: {CFG.BATCH_SIZE}\")\n",
    "print(f\"   Training Epochs: {CFG.EPOCHS}\")\n",
    "\n",
    "# RTX 5090 CUDA optimization settings\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Detected: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    print(\"RTX 5090 optimizations enabled\")\n",
    "    try:\n",
    "        test_tensor = torch.randn(100, 100).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(\"CUDA test passed!\")\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"CUDA test failed: {e}\")\n",
    "        print(\"Please check PyTorch CUDA installation!\")\n",
    "else:\n",
    "    print(\"CUDA unavailable, using CPU mode\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(CFG.SEED, reproducible=True)\n",
    "\n",
    "# Data augmentation transforms\n",
    "def get_transforms():\n",
    "    return aug_transforms(\n",
    "        size=CFG.IMAGE_SIZE,\n",
    "        min_scale=0.7,\n",
    "        max_rotate=20,\n",
    "        max_lighting=0.4,\n",
    "        max_warp=0.25,\n",
    "        p_affine=0.9,\n",
    "        p_lighting=0.9\n",
    "    )\n",
    "\n",
    "# Data preparation\n",
    "print(\"\\nPreparing data...\")\n",
    "\n",
    "# Check if data files exist\n",
    "required_files = [CFG.TRAIN_FEATURES_PATH, CFG.TRAIN_LABELS_PATH, CFG.TEST_FEATURES_PATH]\n",
    "for file_path in required_files:\n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        print(\"Please ensure the following files are in the current directory:\")\n",
    "        print(\"  - train_features.csv\")\n",
    "        print(\"  - train_labels.csv\")\n",
    "        print(\"  - test_features.csv\")\n",
    "        raise FileNotFoundError(f\"Missing required file: {file_path}\")\n",
    "\n",
    "train_features_df = pd.read_csv(CFG.TRAIN_FEATURES_PATH)\n",
    "train_labels_df = pd.read_csv(CFG.TRAIN_LABELS_PATH)\n",
    "test_features_df = pd.read_csv(CFG.TEST_FEATURES_PATH)\n",
    "\n",
    "# Process labels - convert one-hot to categorical\n",
    "# train_labels_df['label'] = train_labels_df.iloc[:, 1:].idxmax(axis=1)\n",
    "train_labels_df['label'] = train_labels_df.iloc[:, 1:].to_numpy().argmax(axis=1)\n",
    "\n",
    "df = train_features_df.merge(train_labels_df[['id', 'label']], on='id')\n",
    "\n",
    "# Create image paths\n",
    "df['image_path'] = df['filepath'].apply(lambda x: CFG.BASE_PATH / x)\n",
    "test_features_df['image_path'] = test_features_df['filepath'].apply(lambda x: CFG.BASE_PATH / x)\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"   Training images: {len(df)}\")\n",
    "print(f\"   Test images: {len(test_features_df)}\")\n",
    "print(f\"   Number of classes: {df['label'].nunique()}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Cross-validation setup\n",
    "print(\"\\nSetting up StratifiedGroupKFold...\")\n",
    "df['fold'] = -1\n",
    "splitter = StratifiedGroupKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "\n",
    "# Assign fold numbers\n",
    "for fold, (train_idx, val_idx) in enumerate(splitter.split(df, df['label'], groups=df['site'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(\"Fold distribution:\")\n",
    "print(df.fold.value_counts())\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\nStarting RTX 5090 Training - {CFG.N_FOLDS} Fold Cross Validation\")\n",
    "\n",
    "val_oof_logits = []\n",
    "all_test_preds = []\n",
    "all_oof_preds = []\n",
    "fold_scores = []\n",
    "raw_test_logits = []\n",
    "\n",
    "\n",
    "vocab = None"
   ],
   "id": "6c6c10aa13113e97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTX 5090 Configuration:\n",
      "   Model: timm/eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\n",
      "   Resolution: 448x448\n",
      "   Batch Size: 16\n",
      "   Training Epochs: 15\n",
      "Detected: NVIDIA GeForce RTX 3090\n",
      "RTX 5090 optimizations enabled\n",
      "CUDA test passed!\n",
      "\n",
      "Preparing data...\n",
      "Data loaded successfully!\n",
      "   Training images: 16488\n",
      "   Test images: 4464\n",
      "   Number of classes: 8\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "6    2492\n",
      "0    2474\n",
      "3    2423\n",
      "5    2254\n",
      "2    2213\n",
      "7    2013\n",
      "1    1641\n",
      "4     978\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Setting up StratifiedGroupKFold...\n",
      "Fold distribution:\n",
      "fold\n",
      "1    4525\n",
      "3    3771\n",
      "2    3244\n",
      "4    2728\n",
      "0    2220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Starting RTX 5090 Training - 5 Fold Cross Validation\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.463435Z",
     "start_time": "2025-09-24T13:31:30.438646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[ 'predict' ] = 0\n",
    "stats['val_oof_labels'] = []\n",
    "\n",
    "for fold in range(CFG.N_FOLDS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} - RTX 5090 Training\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    fold_data = df[ df['fold'] == fold ]\n",
    "\n",
    "    stats['val_oof_labels'].append(fold_data['label'])"
   ],
   "id": "360fac23f57537fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 0 - RTX 5090 Training\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Fold 1 - RTX 5090 Training\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Fold 2 - RTX 5090 Training\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Fold 3 - RTX 5090 Training\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Fold 4 - RTX 5090 Training\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.518276Z",
     "start_time": "2025-09-24T13:31:30.483880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_oof_logits = torch.cat(stats['val_oof_logits'])\n",
    "all_oof_labels = torch.cat([torch.tensor(s.values) for s in stats['val_oof_labels']])"
   ],
   "id": "d763c4fe3ac47812",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.617461Z",
     "start_time": "2025-09-24T13:31:30.578583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_folded = pd.concat([ df[ df['fold'] == fold ] for fold in range(CFG.N_FOLDS) ])\n",
    "\n",
    "train_data_folded"
   ],
   "id": "43d7ba3d8195431b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             id                     filepath   site  label  \\\n",
       "5      ZJ000005  train_features/ZJ000005.jpg  S0019      4   \n",
       "11     ZJ000011  train_features/ZJ000011.jpg  S0014      5   \n",
       "16     ZJ000016  train_features/ZJ000016.jpg  S0105      5   \n",
       "20     ZJ000020  train_features/ZJ000020.jpg  S0105      5   \n",
       "21     ZJ000021  train_features/ZJ000021.jpg  S0068      6   \n",
       "...         ...                          ...    ...    ...   \n",
       "16463  ZJ016463  train_features/ZJ016463.jpg  S0159      4   \n",
       "16471  ZJ016471  train_features/ZJ016471.jpg  S0062      1   \n",
       "16478  ZJ016478  train_features/ZJ016478.jpg  S0062      7   \n",
       "16479  ZJ016479  train_features/ZJ016479.jpg  S0083      1   \n",
       "16483  ZJ016483  train_features/ZJ016483.jpg  S0093      2   \n",
       "\n",
       "                             image_path  fold  predict  \n",
       "5      data/train_features/ZJ000005.jpg     0        0  \n",
       "11     data/train_features/ZJ000011.jpg     0        0  \n",
       "16     data/train_features/ZJ000016.jpg     0        0  \n",
       "20     data/train_features/ZJ000020.jpg     0        0  \n",
       "21     data/train_features/ZJ000021.jpg     0        0  \n",
       "...                                 ...   ...      ...  \n",
       "16463  data/train_features/ZJ016463.jpg     4        0  \n",
       "16471  data/train_features/ZJ016471.jpg     4        0  \n",
       "16478  data/train_features/ZJ016478.jpg     4        0  \n",
       "16479  data/train_features/ZJ016479.jpg     4        0  \n",
       "16483  data/train_features/ZJ016483.jpg     4        0  \n",
       "\n",
       "[16488 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZJ000005</td>\n",
       "      <td>train_features/ZJ000005.jpg</td>\n",
       "      <td>S0019</td>\n",
       "      <td>4</td>\n",
       "      <td>data/train_features/ZJ000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZJ000011</td>\n",
       "      <td>train_features/ZJ000011.jpg</td>\n",
       "      <td>S0014</td>\n",
       "      <td>5</td>\n",
       "      <td>data/train_features/ZJ000011.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ZJ000016</td>\n",
       "      <td>train_features/ZJ000016.jpg</td>\n",
       "      <td>S0105</td>\n",
       "      <td>5</td>\n",
       "      <td>data/train_features/ZJ000016.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZJ000020</td>\n",
       "      <td>train_features/ZJ000020.jpg</td>\n",
       "      <td>S0105</td>\n",
       "      <td>5</td>\n",
       "      <td>data/train_features/ZJ000020.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ZJ000021</td>\n",
       "      <td>train_features/ZJ000021.jpg</td>\n",
       "      <td>S0068</td>\n",
       "      <td>6</td>\n",
       "      <td>data/train_features/ZJ000021.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td>ZJ016463</td>\n",
       "      <td>train_features/ZJ016463.jpg</td>\n",
       "      <td>S0159</td>\n",
       "      <td>4</td>\n",
       "      <td>data/train_features/ZJ016463.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16471</th>\n",
       "      <td>ZJ016471</td>\n",
       "      <td>train_features/ZJ016471.jpg</td>\n",
       "      <td>S0062</td>\n",
       "      <td>1</td>\n",
       "      <td>data/train_features/ZJ016471.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16478</th>\n",
       "      <td>ZJ016478</td>\n",
       "      <td>train_features/ZJ016478.jpg</td>\n",
       "      <td>S0062</td>\n",
       "      <td>7</td>\n",
       "      <td>data/train_features/ZJ016478.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16479</th>\n",
       "      <td>ZJ016479</td>\n",
       "      <td>train_features/ZJ016479.jpg</td>\n",
       "      <td>S0083</td>\n",
       "      <td>1</td>\n",
       "      <td>data/train_features/ZJ016479.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16483</th>\n",
       "      <td>ZJ016483</td>\n",
       "      <td>train_features/ZJ016483.jpg</td>\n",
       "      <td>S0093</td>\n",
       "      <td>2</td>\n",
       "      <td>data/train_features/ZJ016483.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16488 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.697031Z",
     "start_time": "2025-09-24T13:31:30.642662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import temperature_scaling as ts\n",
    "\n",
    "# targets = torch.tensor(ts_df['label'].to_numpy())\n",
    "# ce = F.cross_entropy(logits, targets)\n",
    "\n",
    "t_optim, optim_loss = ts.fit_temperature_lbfgs(all_oof_logits, all_oof_labels)\n",
    "\n",
    "t_optim, optim_loss"
   ],
   "id": "84d08d5fe0821e53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nickolay/workspace/python/conservision_benchmark/.venv/lib/python3.12/site-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  loss = float(closure())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.3095703523498126, 0.6898698816628085)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.735543Z",
     "start_time": "2025-09-24T13:31:30.708014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_oof_preds = F.softmax(all_oof_logits / 1, dim=1)\n",
    "\n",
    "all_oof_class = all_oof_preds.argmax(dim=1)\n",
    "all_oof_max_prob, _ = all_oof_preds.max(dim=1)\n",
    "\n",
    "all_oof_correct = all_oof_class == all_oof_labels\n",
    "\n",
    "all_oof_max_prob"
   ],
   "id": "8e84d79dd01dd4b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9947, 0.3376, 0.9100,  ..., 0.8889, 1.0000, 0.9292])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:31:30.777968Z",
     "start_time": "2025-09-24T13:31:30.756548Z"
    }
   },
   "cell_type": "code",
   "source": "lib.choose_tau_from_val(all_oof_logits, all_oof_labels, target_prec=0.95, min_coverage=0.44)",
   "id": "62f102508ba88bac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has something with both precision and coverage: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9682453870773315, 0.9888352751731873, 0.4400169849395752)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T13:33:31.258412Z",
     "start_time": "2025-09-24T13:33:31.229804Z"
    }
   },
   "cell_type": "code",
   "source": "lib.choose_tau_per_class_from_val(all_oof_logits, all_oof_labels, target_prec=0.95, min_coverage=[0.5, 0.75, 0.04, 0.88, 0.9, 0.78, 0.67, 0.4], measure='margin')",
   "id": "b224a9196b33688d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9223, 0.6173, 0.9298, 0.3379, 0.3293, 0.6965, 0.7603, 0.8500]),\n",
       " tensor([0.9667, 0.9684, 0.9365, 0.9627, 0.9601, 0.9657, 0.9619, 0.9663]),\n",
       " tensor([0.5002, 0.7502, 0.0400, 0.8803, 0.9007, 0.7803, 0.6700, 0.4002]),\n",
       " tensor([2883, 1393, 3150, 2256,  806, 1830, 2391, 1779]),\n",
       " {'p': tensor([[5.0197e-03, 1.6039e-05, 7.9644e-05,  ..., 1.9084e-05, 1.4033e-04,\n",
       "           2.7018e-05],\n",
       "          [2.0657e-01, 1.4820e-01, 3.3759e-01,  ..., 5.9625e-02, 6.6019e-02,\n",
       "           2.2551e-02],\n",
       "          [1.4036e-02, 3.4728e-04, 7.1978e-02,  ..., 9.1003e-01, 2.0680e-03,\n",
       "           8.6264e-06],\n",
       "          ...,\n",
       "          [8.8891e-01, 2.8935e-03, 1.8825e-04,  ..., 1.9553e-05, 7.7637e-05,\n",
       "           1.0700e-01],\n",
       "          [4.7240e-07, 1.0000e+00, 3.9504e-08,  ..., 6.6545e-08, 1.4908e-07,\n",
       "           3.4523e-08],\n",
       "          [3.9732e-03, 9.3420e-04, 9.2915e-01,  ..., 2.1221e-02, 8.6399e-04,\n",
       "           2.2131e-02]]),\n",
       "  'pred': tensor([4, 2, 5,  ..., 0, 1, 2]),\n",
       "  'score': tensor([0.9897, 0.1310, 0.8380,  ..., 0.7819, 1.0000, 0.9070]),\n",
       "  'conf': tensor([0.9947, 0.3376, 0.9100,  ..., 0.8889, 1.0000, 0.9292]),\n",
       "  'correct': tensor([1, 0, 1,  ..., 0, 1, 1], dtype=torch.int32)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:40:30.944665Z",
     "start_time": "2025-09-23T09:40:30.935409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_accs = [s['val_acc'] for s in stats['fold_scores']]\n",
    "val_loss = [s['val_loss'] for s in stats['fold_scores']]\n",
    "\n",
    "weights_acc = torch.softmax(torch.tensor(val_accs) * 5, dim=0)\n",
    "weights_loss = torch.softmax(1 / torch.tensor(val_loss) * 4, dim=0)\n",
    "\n",
    "print(f\"Fold weights by acc: {[f'{w:.3f}' for w in weights_acc.tolist()]}\")\n",
    "print(f\"Fold weights by loss: {[f'{w:.3f}' for w in weights_loss.tolist()]}\")\n"
   ],
   "id": "eff20f493050741f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold weights by acc: ['0.238', '0.219', '0.162', '0.185', '0.196']\n",
      "Fold weights by loss: ['0.294', '0.436', '0.050', '0.125', '0.094']\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:40:54.263970Z",
     "start_time": "2025-09-23T09:40:54.253256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# averaged_test_logits = sum(w * test_logit for w, test_logit in zip(weights_acc, stats['raw_test_logits']))\n",
    "averaged_test_logits = sum(w * test_logit for w, test_logit in zip(weights_loss, stats['raw_test_logits']))\n",
    "\n",
    "# averaged_test_logits = sum(1/5 * test_logit for w, test_logit in zip(weights_acc, stats['raw_test_logits']))"
   ],
   "id": "c0e3344f8deaa688",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:40:56.066501Z",
     "start_time": "2025-09-23T09:40:56.064206Z"
    }
   },
   "cell_type": "code",
   "source": "averaged_test_probs = F.softmax(averaged_test_logits / t_optim, dim=1)",
   "id": "c8c7bdda345b3d03",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:40:57.805314Z",
     "start_time": "2025-09-23T09:40:57.776653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weighted ensemble predictions\n",
    "# ensemble_preds = sum(w * pred for w, pred in zip(weights_acc, raw_test_logits))\n",
    "#\n",
    "# weights_loss = torch.softmax(1 / torch.tensor(val_loss) * 5, dim=0)\n",
    "# print(f\"Fold weights by loss: {[f'{w:.3f}' for w in weights_loss.tolist()]}\")\n",
    "#\n",
    "# # Weighted ensemble predictions\n",
    "# ensemble_preds_loss = sum(w * pred for w, pred in zip(weights_loss, all_test_preds))\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file by accuracy...\")\n",
    "\n",
    "import data\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['id'] + list(data.species_labels))\n",
    "submission_df['id'] = test_features_df['id']\n",
    "submission_df[list(data.species_labels)] = averaged_test_probs.numpy()\n",
    "\n",
    "submission_df.to_csv('submission_fast_ai_k_fold_common_temp.csv', index=False)\n"
   ],
   "id": "fd4c50bd3a558bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating submission file by accuracy...\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 0 - RTX 5090 Training\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m=\u001B[39m\u001B[33m'\u001B[39m*\u001B[32m50\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      8\u001B[39m fold_data = df[ df[\u001B[33m'\u001B[39m\u001B[33mfold\u001B[39m\u001B[33m'\u001B[39m] == fold ]\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m fold_data[\u001B[33m'\u001B[39m\u001B[33mpredict\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mstats\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mval_oof_logits\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Create fold splitter function\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_splitter\u001B[39m(fold_num):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:888\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    885\u001B[39m             stop = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    887\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m plugin_stop:\n\u001B[32m--> \u001B[39m\u001B[32m888\u001B[39m     stopped_on_plugin = \u001B[43mplugin_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain_debugger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_cmd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    889\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m stop:\n\u001B[32m    890\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_line:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/jupyter_debug/pydev_jupyter_plugin.py:185\u001B[39m, in \u001B[36mstop\u001B[39m\u001B[34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[39m\n\u001B[32m    183\u001B[39m     frame = suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m         \u001B[43mmain_debugger\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    186\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    187\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1196\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1193\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1196\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1211\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1208\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1210\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1211\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1213\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1215\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "\n",
    "\n",
    "    # Create fold splitter function\n",
    "    def get_splitter(fold_num):\n",
    "        def _inner(o):\n",
    "            val_mask = o['fold'] == fold_num\n",
    "            train_mask = o['fold'] != fold_num\n",
    "            return o.index[train_mask], o.index[val_mask]\n",
    "        return _inner\n",
    "\n",
    "    # DataBlock configuration\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_x=ColReader('image_path'),\n",
    "        get_y=ColReader(CFG.TARGET_COL),\n",
    "        splitter=get_splitter(fold),\n",
    "        item_tfms=Resize(CFG.IMAGE_SIZE, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
    "        batch_tfms=[*get_transforms(), Normalize.from_stats(*imagenet_stats)]\n",
    "    )\n",
    "\n",
    "    print(f\"Creating DataLoaders (batch size: {CFG.BATCH_SIZE})...\")\n",
    "\n",
    "    # Create DataLoaders with RTX 5090 optimizations\n",
    "    if torch.cuda.is_available():\n",
    "        dls = dblock.dataloaders(\n",
    "            df,\n",
    "            bs=CFG.BATCH_SIZE,\n",
    "            num_workers=CFG.NUM_WORKERS,\n",
    "            pin_memory=CFG.PIN_MEMORY,\n",
    "            prefetch_factor=CFG.PREFETCH_FACTOR\n",
    "        )\n",
    "    else:\n",
    "        dls = dblock.dataloaders(\n",
    "            df,\n",
    "            bs=16,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    # Store vocabulary from first fold\n",
    "    if vocab is None:\n",
    "        vocab = dls.vocab\n",
    "        print(f\"Class vocabulary: {list(vocab)}\")\n",
    "\n",
    "    print(f\"Creating {CFG.MODEL_ARCHITECTURE} model...\")\n",
    "\n",
    "    # Setup callbacks for training\n",
    "    cbs = [\n",
    "        EarlyStoppingCallback(monitor='valid_loss', patience=3),\n",
    "        SaveModelCallback(monitor='valid_loss', fname=f'best_model_fold_{fold}')\n",
    "    ]\n",
    "\n",
    "    # Create learner with mixed precision\n",
    "    learn = vision_learner(\n",
    "        dls,\n",
    "        CFG.MODEL_ARCHITECTURE,\n",
    "        metrics=[error_rate, accuracy],\n",
    "        cbs=cbs\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.load(f'best_model_fold_{fold}', device='cuda')\n",
    "\n",
    "    # print(f\"Starting training for {CFG.EPOCHS} epochs...\")\n",
    "    #\n",
    "    # # Find optimal learning rate\n",
    "    # try:\n",
    "    #     lr_min, lr_steep = learn.lr_find()\n",
    "    #     print(f\"Suggested learning rate: {lr_steep:.2e}\")\n",
    "    #     final_lr = lr_steep\n",
    "    # except Exception as e:\n",
    "    #     print(\"Using default learning rate\", e)\n",
    "    #     final_lr = CFG.BASE_LR\n",
    "    #\n",
    "    # # Train the model\n",
    "    # learn.fit_one_cycle(CFG.EPOCHS, lr_max=final_lr)\n",
    "\n",
    "    ts_df = learn.dls.valid_ds.items\n",
    "    ts_dl = learn.dls.test_dl(ts_df)\n",
    "    logits, _ = learn.get_preds(dl=ts_dl, act=lambda x: x)\n",
    "\n",
    "    val_oof_logits.append(logits)\n",
    "\n",
    "    import temperature_scaling as ts\n",
    "\n",
    "    targets = torch.tensor(ts_df['label'].to_numpy())\n",
    "    ce = F.cross_entropy(logits, targets)\n",
    "\n",
    "    t_optim, optim_loss = ts.fit_temperature_lbfgs(logits, targets)\n",
    "\n",
    "    # Record validation scores\n",
    "    # val_results = learn.validate()\n",
    "    val_loss = optim_loss\n",
    "    # val_loss = float(val_results[0])\n",
    "    # val_acc = float(val_results[2])  # accuracy is the 2nd metric\n",
    "\n",
    "    val_acc = F.softmax(logits / t_optim, dim=1).argmax(dim=1).eq(targets).float().mean().item()\n",
    "\n",
    "    fold_scores.append({'fold': fold, 'val_loss': val_loss, 'val_acc': val_acc, 't_optim': t_optim})\n",
    "    print(f\"Fold {fold} validation results: Loss={ce:.4f}, Optimized loss: {val_loss:.4f}, Optim temeprature={t_optim:.4f}, Acc={val_acc:.4f}\")\n",
    "\n",
    "    # Generate test predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    test_dl = dls.test_dl(test_features_df)\n",
    "    preds, _ = learn.get_preds(dl=test_dl, act=lambda x: x)\n",
    "\n",
    "    raw_test_logits.append(preds)\n",
    "\n",
    "    preds = F.softmax(preds / t_optim, dim=1)\n",
    "\n",
    "    all_test_preds.append(preds)\n",
    "\n",
    "    # Get out-of-fold predictions\n",
    "    # val_dl = dls.valid\n",
    "    # oof_preds, _ = learn.get_preds(dl=val_dl)\n",
    "    # all_oof_preds.append(oof_preds)\n",
    "\n",
    "    # Memory cleanup\n",
    "    print(\"Memory cleanup...\")\n",
    "    del learn, dls, test_dl\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "with open(\"fast_ai_k_fold_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        'val_oof_logits': val_oof_logits,\n",
    "        'all_test_preds': all_test_preds,\n",
    "        'all_oof_preds': all_oof_preds,\n",
    "        'fold_scores': fold_scores,\n",
    "        'raw_test_logits': raw_test_logits,\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RTX 5090 Training Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Display fold results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for score in fold_scores:\n",
    "    print(f\"Fold {score['fold']}: Loss={score['val_loss']:.4f}, Acc={score['val_acc']:.4f}\")\n",
    "\n",
    "avg_loss = np.mean([s['val_loss'] for s in fold_scores])\n",
    "avg_acc = np.mean([s['val_acc'] for s in fold_scores])\n",
    "print(f\"\\nAverage performance: Loss={avg_loss:.4f}, Acc={avg_acc:.4f}\")\n",
    "\n",
    "# Ensemble strategy - weighted by validation performance\n",
    "print(f\"\\nExecuting ensemble strategy...\")\n",
    "\n",
    "val_accs = [s['val_acc'] for s in fold_scores]\n",
    "val_loss = [s['val_loss'] for s in fold_scores]\n",
    "\n",
    "weights_acc = torch.softmax(torch.tensor(val_accs) * 5, dim=0)\n",
    "print(f\"Fold weights by acc: {[f'{w:.3f}' for w in weights_acc.tolist()]}\")\n",
    "\n",
    "# Weighted ensemble predictions\n",
    "ensemble_preds = sum(w * pred for w, pred in zip(weights_acc, all_test_preds))\n",
    "\n",
    "weights_loss = torch.softmax(1 / torch.tensor(val_loss) * 5, dim=0)\n",
    "print(f\"Fold weights by loss: {[f'{w:.3f}' for w in weights_loss.tolist()]}\")\n",
    "\n",
    "# Weighted ensemble predictions\n",
    "ensemble_preds_loss = sum(w * pred for w, pred in zip(weights_loss, all_test_preds))\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file by accuracy...\")\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['id'] + list(vocab))\n",
    "submission_df['id'] = test_features_df['id']\n",
    "submission_df[list(vocab)] = ensemble_preds.numpy()\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv('submission_fast_ai_k_fold_accuracy.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"\\nCreating submission file by loss...\")\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['id'] + list(vocab))\n",
    "submission_df['id'] = test_features_df['id']\n",
    "submission_df[list(vocab)] = ensemble_preds_loss.numpy()\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv('submission_fast_ai_k_fold_loss.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RTX 5090 Submission File Created!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"=== Configuration Summary ===\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Model: {CFG.MODEL_ARCHITECTURE}\")\n",
    "print(f\"Resolution: {CFG.IMAGE_SIZE}x{CFG.IMAGE_SIZE}\")\n",
    "print(f\"Batch Size: {CFG.BATCH_SIZE}\")\n",
    "print(f\"Total Training Epochs: {CFG.N_FOLDS * CFG.EPOCHS}\")\n",
    "print(f\"Average Validation Accuracy: {avg_acc:.4f}\")\n",
    "print(f\"Mixed Precision Training: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "print(\"\")\n",
    "print(\"Submission file: rtx5090_submission.csv\")\n",
    "print(\"Ready to dominate the competition!\")"
   ],
   "id": "3bf558e30852bb17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}