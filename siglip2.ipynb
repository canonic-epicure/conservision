{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:19.129506Z",
     "start_time": "2025-09-04T10:46:19.113184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:19.155486Z",
     "start_time": "2025-09-04T10:46:19.138983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "import data\n",
    "import lib"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model instantiation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:20.623029Z",
     "start_time": "2025-09-04T10:46:19.187912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "restore_checkpoint: bool = False\n",
    "\n",
    "model_id = \"google/siglip2-large-patch16-384\"  # FixRes вариант\n",
    "model_preprocessor = AutoImageProcessor.from_pretrained(model_id)  # даст resize/normalize, mean/std/size\n",
    "\n",
    "optimizer = None\n",
    "\n",
    "if restore_checkpoint:\n",
    "    epochs = lib.model_checkpoints(f'./models_siglip2/checkpoint_*.pth')\n",
    "\n",
    "    if len(epochs) == 0:\n",
    "        print('no models found')\n",
    "        raise ValueError('No model found')\n",
    "\n",
    "    print(f'Loading model from epoch { epochs[ 0 ] }')\n",
    "\n",
    "    checkpoint = torch.load(f'./models_siglip2/checkpoint_{ epochs[ 0 ] }.pth', weights_only=False)\n",
    "\n",
    "    model = checkpoint['model']\n",
    "    optimizer = checkpoint['optimizer']\n",
    "else:\n",
    "    # Веса энкодера + НОВАЯ голова классификации (num_labels=2):\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        model_id,\n",
    "        num_labels=len(data.species_labels),\n",
    "        ignore_mismatched_sizes=True,  # создаст новую голову нужного размера\n",
    "    )\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    model.tracking_loss = []\n",
    "    model.tracking_loss_val = []\n",
    "    model.epoch = 0\n",
    "\n",
    "tracking_loss = model.tracking_loss\n",
    "tracking_loss_val = model.tracking_loss_val"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f739b584bf20496d9e2bed62684372f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SiglipForImageClassification were not initialized from the model checkpoint at google/siglip2-large-patch16-384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:20.686689Z",
     "start_time": "2025-09-04T10:46:20.672508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds = lib.ImageDatasetSigLip2(data.x_train, data.y_train, processor=model_preprocessor, learning=True)\n",
    "val_ds   = lib.ImageDatasetSigLip2(data.x_eval, data.y_eval, processor=model_preprocessor, learning=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=4)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Freezing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:20.731804Z",
     "start_time": "2025-09-04T10:46:20.718062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unfreezing: Literal['classifier_only', 'classifier_and_encoder', 'all'] = 'classifier_only'\n",
    "\n",
    "# C) Параметрические группы с «ступенчатым» LR: у головы LR выше, у энкодера ниже\n",
    "head_params = []\n",
    "enc_params  = []\n",
    "\n",
    "if unfreezing == 'classifier_only':\n",
    "    # 2) Заморозим всё, кроме головы (линейный пробинг)\n",
    "    for name, p in model.named_parameters():\n",
    "        p.requires_grad = \"classifier\" in name  # у HF-классификаторов голова обычно называется \"classifier\"\n",
    "\n",
    "        if \"classifier\" in name:\n",
    "            head_params.append(p)\n",
    "\n",
    "elif unfreezing == 'classifier_and_encoder':\n",
    "    # A) Сначала всё заморозим\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"classifier\" in name:\n",
    "            p.requires_grad = True  # голова остаётся обучаемой\n",
    "            head_params.append(p)\n",
    "\n",
    "    # B) Разморозим последние L блоков визуального энкодера\n",
    "    L = 4  # начните с 2–4; при достаточном VRAM можно 6–8\n",
    "    layers = model.vision_model.encoder.layers   # ModuleList\n",
    "    for block in layers[-L:]:\n",
    "        for p in block.parameters():\n",
    "            p.requires_grad = True\n",
    "            enc_params.append(p)\n",
    "elif unfreezing == 'all':\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "else:\n",
    "    raise ValueError(f\"Unknown unfreezing mode: {unfreezing}\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss (possibly with weights)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:20.778170Z",
     "start_time": "2025-09-04T10:46:20.764667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4) Баланс классов (простой вариант: веса в CrossEntropy по частотам)\n",
    "# import numpy as np\n",
    "# counts = np.bincount(train_labels, minlength=2)  # counts[0], counts[1]\n",
    "# class_weights = torch.tensor((counts.sum() / (2.0 * np.maximum(counts, 1))), dtype=torch.float32, device=device)\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Optimizer"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:46:20.827497Z",
     "start_time": "2025-09-04T10:46:20.813581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if optimizer is None:\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": enc_params,  \"lr\": 1e-4, \"weight_decay\": 0.05},\n",
    "            {\"params\": head_params, \"lr\": 1e-3, \"weight_decay\": 0.01},\n",
    "        ]\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loop"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-04T10:46:20.861333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(model.epoch, model.epoch + num_epochs):\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    print(f\"Training: \")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_acc = 0\n",
    "    count = 0\n",
    "\n",
    "    for batch in tqdm.tqdm(train_loader, total=len(train_loader), ):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        out = model(batch['pixel_values'].to('cuda'))              # logits: (B, 2)\n",
    "        loss = criterion(out.logits, batch[\"labels\"].to('cuda'))\n",
    "\n",
    "        c = batch['pixel_values'].size(0)\n",
    "        loss_acc += loss.item() * c\n",
    "        count += c\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tracking_loss.append(loss_acc / count)\n",
    "\n",
    "    # валидация\n",
    "    model.eval()\n",
    "\n",
    "    loss_acc = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(val_loader, total=len(val_loader)):\n",
    "            out = model(batch['pixel_values'].to('cuda'))\n",
    "            loss = criterion(out.logits, batch[\"labels\"].to('cuda'))\n",
    "\n",
    "            c = batch['pixel_values'].size(0)\n",
    "            loss_acc += loss.item() * c\n",
    "            count += c\n",
    "\n",
    "    tracking_loss_val.append(loss_acc / count)\n",
    "\n",
    "    lib.save_model(model, optimizer, f\"./models_siglip2/checkpoint_{str(epoch).rjust(2, \"0\")}.pth\")\n",
    "\n",
    "    model.epoch += 1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]/home/nickolay/workspace/python/conservision_benchmark/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `SiglipImageProcessor.preprocess` and were ignored: 'do_center_crop'\n",
      "  return self.preprocess(images, **kwargs)\n",
      "/home/nickolay/workspace/python/conservision_benchmark/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `SiglipImageProcessor.preprocess` and were ignored: 'do_center_crop'\n",
      "  return self.preprocess(images, **kwargs)\n",
      "/home/nickolay/workspace/python/conservision_benchmark/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `SiglipImageProcessor.preprocess` and were ignored: 'do_center_crop'\n",
      "  return self.preprocess(images, **kwargs)\n",
      "/home/nickolay/workspace/python/conservision_benchmark/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `SiglipImageProcessor.preprocess` and were ignored: 'do_center_crop'\n",
      "  return self.preprocess(images, **kwargs)\n",
      " 10%|▉         | 5/52 [00:34<04:50,  6.18s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training progress"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tracking_loss, tracking_loss_val",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "epochs_train = list(range(len(tracking_loss)))\n",
    "epochs_val = list(range(len(tracking_loss_val)))\n",
    "ax.plot(epochs_train, tracking_loss, label=\"train loss\")\n",
    "ax.plot(epochs_val, tracking_loss_val, label=\"validation loss\", alpha=0.8)\n",
    "ax.set_xlabel(\"Epoch (index)\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xticks(epochs_train)\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict(model, data_loader: DataLoader, T = 1):\n",
    "    preds_collector = []\n",
    "\n",
    "    # put the model in eval mode so we don't update any parameters\n",
    "    model.eval()\n",
    "\n",
    "    model.to(torch.device(\"cuda\"))\n",
    "\n",
    "    # we aren't updating our weights so no need to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, total=len(data_loader)):\n",
    "            # 1) run the forward step\n",
    "            logits = model.forward(batch[\"pixel_values\"].to(torch.device(\"cuda\"))).logits\n",
    "            # 2) apply softmax so that model outputs are in range [0,1]\n",
    "            preds = nn.functional.softmax(logits / T, dim=1)\n",
    "            # 3) store this batch's predictions in df\n",
    "            # note that PyTorch Tensors need to first be detached from their computational graph before converting to numpy arrays\n",
    "            preds_df = pd.DataFrame(\n",
    "                preds.detach().to('cpu').numpy(),\n",
    "                index=batch[\"image_id\"],\n",
    "                columns=data.species_labels,\n",
    "            )\n",
    "            preds_collector.append(preds_df)\n",
    "\n",
    "    return pd.concat(preds_collector)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "eval_preds_df = predict(model, val_loader)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"True labels (training):\")\n",
    "data.y_train.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Predicted labels (eval):\")\n",
    "eval_preds_df.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"True labels (eval):\")\n",
    "data.y_eval.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_predictions = eval_preds_df.idxmax(axis=1)\n",
    "eval_true = data.y_eval.idxmax(axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correct = (eval_predictions == eval_true).sum()\n",
    "accuracy = correct / len(eval_predictions)\n",
    "accuracy.item()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confusion matrix"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = ConfusionMatrixDisplay.from_predictions(\n",
    "    data.y_eval.idxmax(axis=1),\n",
    "    eval_preds_df.idxmax(axis=1),\n",
    "    ax=ax,\n",
    "    xticks_rotation=30,\n",
    "    colorbar=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create submission"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = lib.ImageDatasetSigLip2(data.test_features, learning=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission_df = predict(model, test_dataloader)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission_format = pd.read_csv(\"data/submission_format.csv\", index_col=\"id\")\n",
    "\n",
    "assert all(submission_df.index == submission_format.index)\n",
    "assert all(submission_df.columns == submission_format.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission_df.to_csv(\"submission.csv\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
